/home/mmuhleth/discrete_diffusion_graph/utils/graphs.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_matrix = loss_matrix * (1-2*torch.tensor(sigma_list).unsqueeze(-1).unsqueeze(-2).expand(grad_log_q_noise_list.size(0),grad_log_q_noise_list.size(1),grad_log_q_noise_list.size(2)).to(device)+1.0/len(sigma_list))
/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 1/100, Loss: 0.20457141217775643
Epoch 2/100, Loss: 0.07078847044613212
Epoch 3/100, Loss: 0.057568041142076254
Epoch 4/100, Loss: 0.04857850563712418
Epoch 5/100, Loss: 0.04486253345385194
Epoch 6/100, Loss: 0.042691773851402104
Epoch 7/100, Loss: 0.04130964947398752
Epoch 8/100, Loss: 0.04388719517737627
Epoch 9/100, Loss: 0.041104186908341944
Epoch 10/100, Loss: 0.04036183876451105
Epoch 11/100, Loss: 0.040633320808410645
Epoch 12/100, Loss: 0.03974727093009278
Epoch 13/100, Loss: 0.04069078457541764
Epoch 14/100, Loss: 0.0403227461501956
Epoch 15/100, Loss: 0.038640537299215794
Epoch 16/100, Loss: 0.04030861333012581
Epoch 17/100, Loss: 0.04013197240419686
Epoch 18/100, Loss: 0.03875191020779312
Epoch 19/100, Loss: 0.03860222944058478
Epoch 20/100, Loss: 0.039459275314584374
Epoch 21/100, Loss: 0.038271108467597514
Epoch 22/100, Loss: 0.03912547347135842
Epoch 23/100, Loss: 0.03838471107883379
Epoch 24/100, Loss: 0.039064975222572684
Epoch 25/100, Loss: 0.038096237869467586
Epoch 26/100, Loss: 0.03837204142473638
Epoch 27/100, Loss: 0.03817292442545295
Epoch 28/100, Loss: 0.03856742288917303
Epoch 29/100, Loss: 0.03717082052025944
Epoch 30/100, Loss: 0.03799600008642301
Epoch 31/100, Loss: 0.0381980394013226
Epoch 32/100, Loss: 0.037907063437160105
Epoch 33/100, Loss: 0.03785744175547734
Epoch 34/100, Loss: 0.038832823978737
Epoch 35/100, Loss: 0.038235745625570416
Epoch 36/100, Loss: 0.03718207514612004
Epoch 37/100, Loss: 0.037986021023243666
Epoch 38/100, Loss: 0.036466665973421186
Epoch 39/100, Loss: 0.03773722820915282
Epoch 40/100, Loss: 0.03743090957868844
Epoch 41/100, Loss: 0.03653699951246381
Epoch 42/100, Loss: 0.036718379298690706
Epoch 43/100, Loss: 0.03613117418717593
Epoch 44/100, Loss: 0.03717763244640082
Epoch 45/100, Loss: 0.03658694424666464
Epoch 46/100, Loss: 0.03846819885075092
Epoch 47/100, Loss: 0.03722632030257955
Epoch 48/100, Loss: 0.038262674992438406
Epoch 49/100, Loss: 0.038081892824266106
Epoch 50/100, Loss: 0.0363398163462989
Epoch 51/100, Loss: 0.0373007309390232
Epoch 52/100, Loss: 0.03791888162959367
Epoch 53/100, Loss: 0.037031035812105983
Epoch 54/100, Loss: 0.03709782660007477
Epoch 55/100, Loss: 0.037105255061760545
Epoch 56/100, Loss: 0.03681883693207055
Epoch 57/100, Loss: 0.03657925082370639
Epoch 58/100, Loss: 0.03723816422279924
Epoch 59/100, Loss: 0.036615438060835004
Epoch 60/100, Loss: 0.03693350497633219
Epoch 61/100, Loss: 0.037545624596532434
Epoch 62/100, Loss: 0.03764821501681581
Epoch 63/100, Loss: 0.037570502259768546
Epoch 64/100, Loss: 0.03688791603781283
Epoch 65/100, Loss: 0.03704431018559262
Epoch 66/100, Loss: 0.036080508085433394
Epoch 67/100, Loss: 0.03703391767339781
Epoch 68/100, Loss: 0.03777687804540619
Epoch 69/100, Loss: 0.036866951966658235
Epoch 70/100, Loss: 0.0375171055784449
Epoch 71/100, Loss: 0.03672312060371041
Epoch 72/100, Loss: 0.03625710413325578
Epoch 73/100, Loss: 0.03634520847117528
Epoch 74/100, Loss: 0.03596583614125848
Epoch 75/100, Loss: 0.03614440554520115
Epoch 76/100, Loss: 0.03651311981957406
Epoch 77/100, Loss: 0.0365279596298933
Epoch 78/100, Loss: 0.03666042321128771
Epoch 79/100, Loss: 0.037189962225966156
Epoch 80/100, Loss: 0.03731555386912078
Epoch 81/100, Loss: 0.0365606308914721
Epoch 82/100, Loss: 0.03660054341889918
Epoch 83/100, Loss: 0.0359107771073468
Epoch 84/100, Loss: 0.03742658201372251
Epoch 85/100, Loss: 0.036381797515787184
Epoch 86/100, Loss: 0.03771231940481812
Epoch 87/100, Loss: 0.03612168680410832
Epoch 88/100, Loss: 0.036662094527855515
Epoch 89/100, Loss: 0.036642926454078406
Epoch 90/100, Loss: 0.036163795506581664
Epoch 91/100, Loss: 0.036238130647689104
Epoch 92/100, Loss: 0.037030802632216364
Epoch 93/100, Loss: 0.037256734212860465
Epoch 94/100, Loss: 0.03771053033415228
Epoch 95/100, Loss: 0.03610323934117332
Epoch 96/100, Loss: 0.036002405860926956
Epoch 97/100, Loss: 0.0368292853818275
Epoch 98/100, Loss: 0.03715000534430146
Epoch 99/100, Loss: 0.03571677778381854
Epoch 100/100, Loss: 0.036437199683859944