/opt/anaconda3/envs/digress/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 1/100, Loss: 0.19731026314772093
Epoch 2/100, Loss: 0.12307738111569332
Epoch 3/100, Loss: 0.11578052662886106
Epoch 4/100, Loss: 0.11694611379733452
Epoch 5/100, Loss: 0.10476083537706962
Epoch 6/100, Loss: 0.10873774267159976
Epoch 7/100, Loss: 0.1022148596552702
Epoch 8/100, Loss: 0.09894629567861557
Epoch 9/100, Loss: 0.09915576359400383
Epoch 10/100, Loss: 0.10204106798538795
Epoch 11/100, Loss: 0.10255144364558734
Epoch 12/100, Loss: 0.1049940912769391
Epoch 13/100, Loss: 0.10422665855059257
Epoch 14/100, Loss: 0.09989059487214455
Epoch 15/100, Loss: 0.10381640092684673
Epoch 16/100, Loss: 0.10691713770994773
Epoch 17/100, Loss: 0.09914388278355965
Epoch 18/100, Loss: 0.10057779172292122
Epoch 19/100, Loss: 0.10866543192129868
Epoch 20/100, Loss: 0.10256197188909237
Epoch 21/100, Loss: 0.10558425233914302
Epoch 22/100, Loss: 0.10290896376738182
Epoch 23/100, Loss: 0.10370060801506042
Epoch 24/100, Loss: 0.1002212636745893
Epoch 25/100, Loss: 0.1029028886785874
Epoch 26/100, Loss: 0.10494607056562717
Epoch 27/100, Loss: 0.10304099894486941
Epoch 28/100, Loss: 0.10197022671882923
Epoch 29/100, Loss: 0.10466402482527953
Epoch 30/100, Loss: 0.10127653353489362
Epoch 31/100, Loss: 0.09772656342157951
Epoch 32/100, Loss: 0.10792090342595027
Epoch 33/100, Loss: 0.10157240468722123
Epoch 34/100, Loss: 0.0992039699967091
Epoch 35/100, Loss: 0.10662193825611702
Epoch 36/100, Loss: 0.10055567037600738
Epoch 37/100, Loss: 0.10327500735337918
Epoch 38/100, Loss: 0.10269178335483257
Epoch 39/100, Loss: 0.10234760951537353
Epoch 40/100, Loss: 0.10233695747760627
Epoch 41/100, Loss: 0.104811847783052
Epoch 42/100, Loss: 0.10246385404696831
Epoch 43/100, Loss: 0.10159359815028998
Epoch 44/100, Loss: 0.10032995904867466
Epoch 45/100, Loss: 0.10466030870492642
Epoch 46/100, Loss: 0.10080880786363895
Epoch 47/100, Loss: 0.10261292984852424
Epoch 48/100, Loss: 0.10136805933255416
Epoch 49/100, Loss: 0.09802949543182667
Epoch 50/100, Loss: 0.09760044572445062
Epoch 51/100, Loss: 0.10598099231719971
Epoch 52/100, Loss: 0.10162738767954019
Epoch 53/100, Loss: 0.10255254060029984
Epoch 54/100, Loss: 0.09888667441331424
Epoch 55/100, Loss: 0.10548712485111676
Epoch 56/100, Loss: 0.1022439581843523
Epoch 57/100, Loss: 0.10368218846046008
Epoch 58/100, Loss: 0.10138858338961235
Epoch 59/100, Loss: 0.09856966424446839
Epoch 60/100, Loss: 0.09642161428928375
Epoch 61/100, Loss: 0.09917612087268096
Epoch 62/100, Loss: 0.10322651496300331
Epoch 63/100, Loss: 0.10470151729308642
Epoch 64/100, Loss: 0.10109614982054783
Epoch 65/100, Loss: 0.10168806520792154
Epoch 66/100, Loss: 0.10287563502788544
Epoch 67/100, Loss: 0.09912058539115466
Epoch 68/100, Loss: 0.10639767864575753
Epoch 69/100, Loss: 0.1044366995875652
Epoch 70/100, Loss: 0.10254372312472416
Epoch 71/100, Loss: 0.10166367716514148
Epoch 72/100, Loss: 0.10395903598803741
Epoch 73/100, Loss: 0.10656772553920746
Epoch 74/100, Loss: 0.09835156339865464
Epoch 75/100, Loss: 0.09908520373014304
Epoch 76/100, Loss: 0.10601276847032401
Epoch 77/100, Loss: 0.10278869936099419
Epoch 78/100, Loss: 0.10123989043327478
Epoch 79/100, Loss: 0.10095097067264411
Epoch 80/100, Loss: 0.09880002530721518
Epoch 81/100, Loss: 0.10195212008861396
Epoch 82/100, Loss: 0.10042902884575036
Epoch 83/100, Loss: 0.10122159639230141
Epoch 84/100, Loss: 0.10320850289784946
Epoch 85/100, Loss: 0.09884790101876625
Epoch 86/100, Loss: 0.09877692277614887
Epoch 87/100, Loss: 0.10615526254360493
Epoch 88/100, Loss: 0.10009534198504227
Epoch 89/100, Loss: 0.10231935175565574
Epoch 90/100, Loss: 0.10311383754014969
Epoch 91/100, Loss: 0.0993397138439692
Epoch 92/100, Loss: 0.10552145941899373
Epoch 93/100, Loss: 0.10282740340783046
Epoch 94/100, Loss: 0.107352247604957
Epoch 95/100, Loss: 0.09612716963657966
Epoch 96/100, Loss: 0.10145736428407523
Epoch 97/100, Loss: 0.09977915596503478
Epoch 98/100, Loss: 0.10334514539975387
Epoch 99/100, Loss: 0.0985134536257157
Epoch 100/100, Loss: 0.10191640659020497