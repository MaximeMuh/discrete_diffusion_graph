/Users/mmuhleth/Desktop/diffusion_graph/utils/graphs.py:183: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  mask = torch.tensor(mask, dtype=torch.float32).to(device)
Epoch 1/100, Loss: 0.28350328421220183
/opt/anaconda3/envs/digress/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2/100, Loss: 0.08129378035664558
Epoch 3/100, Loss: 0.0681999766966328
Epoch 4/100, Loss: 0.05793614452704787
Epoch 5/100, Loss: 0.05433935625478625
Epoch 6/100, Loss: 0.05338770232629031
Epoch 7/100, Loss: 0.05119239690247923
Epoch 8/100, Loss: 0.05526526237372309
Epoch 9/100, Loss: 0.048399356892332435
Epoch 10/100, Loss: 0.04678565845824778
Epoch 11/100, Loss: 0.047420085058547556
Epoch 12/100, Loss: 0.045004086452536285
Epoch 13/100, Loss: 0.04499656718689948
Epoch 14/100, Loss: 0.04451995005365461
Epoch 15/100, Loss: 0.043546626809984446
Epoch 16/100, Loss: 0.044006139622069895
Epoch 17/100, Loss: 0.045124055934138596
Epoch 18/100, Loss: 0.04279632610268891
Epoch 19/100, Loss: 0.044822032446973026
Epoch 20/100, Loss: 0.04390966193750501
Epoch 21/100, Loss: 0.04412748455069959
Epoch 22/100, Loss: 0.04373757459688932
Epoch 23/100, Loss: 0.04404341848567128
Epoch 24/100, Loss: 0.044891717145219445
Epoch 25/100, Loss: 0.04284579446539283
Epoch 26/100, Loss: 0.04494160530157387
Epoch 27/100, Loss: 0.04234468995127827
Epoch 28/100, Loss: 0.043023837730288506
Epoch 29/100, Loss: 0.04274483420886099
Epoch 30/100, Loss: 0.04301099292933941
Epoch 31/100, Loss: 0.0422548163915053
Epoch 32/100, Loss: 0.04322815453633666
Epoch 33/100, Loss: 0.04093163216020912
Epoch 34/100, Loss: 0.04253309569321573
Epoch 35/100, Loss: 0.04220001038629562
Epoch 36/100, Loss: 0.042975148535333574
Epoch 37/100, Loss: 0.04272237222176045
Epoch 38/100, Loss: 0.0437735595041886
Epoch 39/100, Loss: 0.04221694660373032
Epoch 40/100, Loss: 0.04142668598797172
Epoch 41/100, Loss: 0.04308554937597364
Epoch 42/100, Loss: 0.041132289567030966
Epoch 43/100, Loss: 0.04343126772437245
Epoch 44/100, Loss: 0.04128105903510004
Epoch 45/100, Loss: 0.04076151747722179
Epoch 46/100, Loss: 0.04142100701574236
Epoch 47/100, Loss: 0.04189426003722474
Epoch 48/100, Loss: 0.04213579627685249
Epoch 49/100, Loss: 0.04145407641772181
Epoch 50/100, Loss: 0.040824306779541075
Epoch 51/100, Loss: 0.04097636113874614
Epoch 52/100, Loss: 0.041789959534071386
Epoch 53/100, Loss: 0.04025193187408149
Epoch 54/100, Loss: 0.04146708769258112
Epoch 55/100, Loss: 0.041497952421195805
Epoch 56/100, Loss: 0.04096034017857164
Epoch 57/100, Loss: 0.04114967002533376
Epoch 58/100, Loss: 0.04127502255141735
Epoch 59/100, Loss: 0.04017745109740645
Epoch 60/100, Loss: 0.041214061668142676
Epoch 61/100, Loss: 0.04083459445973858
Epoch 62/100, Loss: 0.040673197829164565
Epoch 63/100, Loss: 0.041994523257017136
Epoch 64/100, Loss: 0.04090050439117476
Epoch 65/100, Loss: 0.04028313356684521
Epoch 66/100, Loss: 0.04075664165429771
Epoch 67/100, Loss: 0.04052082123234868
Epoch 68/100, Loss: 0.04138168506324291
Epoch 69/100, Loss: 0.04024719272274524
Epoch 70/100, Loss: 0.04097367264330387
Epoch 71/100, Loss: 0.042573931510560215
Epoch 72/100, Loss: 0.041013281675986946
Epoch 73/100, Loss: 0.040042302338406444
Epoch 74/100, Loss: 0.04084421292645857
Epoch 75/100, Loss: 0.04114538920111954
Epoch 76/100, Loss: 0.04005833703558892
Epoch 77/100, Loss: 0.041420518420636654
Epoch 78/100, Loss: 0.041139436536468565
Epoch 79/100, Loss: 0.04120831546606496
Epoch 80/100, Loss: 0.040867365314625204
Epoch 81/100, Loss: 0.03943380853161216
Epoch 82/100, Loss: 0.0404688945855014
Epoch 83/100, Loss: 0.04031033022329211
Epoch 84/100, Loss: 0.03962897905148566
Epoch 85/100, Loss: 0.041031524538993835
Epoch 86/100, Loss: 0.040245187701657414
Epoch 87/100, Loss: 0.04220173368230462
Epoch 88/100, Loss: 0.040757744456641376
Epoch 89/100, Loss: 0.04119324521161616
Epoch 90/100, Loss: 0.04003403498791158
Epoch 91/100, Loss: 0.041422497597523034
Epoch 92/100, Loss: 0.039612657274119556
Epoch 93/100, Loss: 0.0416529638459906
Epoch 94/100, Loss: 0.040744876372627914
Epoch 95/100, Loss: 0.040527508477680385
Epoch 96/100, Loss: 0.04057542805094272
Epoch 97/100, Loss: 0.040993172908201814
Epoch 98/100, Loss: 0.0402524572564289
Epoch 99/100, Loss: 0.04191685118712485
Epoch 100/100, Loss: 0.041302223689854145