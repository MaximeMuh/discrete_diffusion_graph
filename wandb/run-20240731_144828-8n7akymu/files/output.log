/opt/anaconda3/envs/digress/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 1/100, Loss: 0.3388063348829746
Epoch 2/100, Loss: 0.2590430579148233
Epoch 3/100, Loss: 0.2471845899708569
Epoch 4/100, Loss: 0.2498560850508511
Epoch 5/100, Loss: 0.24584271851927042
Epoch 6/100, Loss: 0.24560426827520132
Epoch 7/100, Loss: 0.24183607334271073
Epoch 8/100, Loss: 0.21212100191041827
Epoch 9/100, Loss: 0.20717070437967777
Epoch 10/100, Loss: 0.19797657895833254
Epoch 11/100, Loss: 0.18808430759236217
Epoch 12/100, Loss: 0.16271199006587267
Epoch 13/100, Loss: 0.1229236819781363
Epoch 14/100, Loss: 0.0832558951806277
Epoch 15/100, Loss: 0.06882207479793578
Epoch 16/100, Loss: 0.06180054240394384
Epoch 17/100, Loss: 0.055809450102970004
Epoch 18/100, Loss: 0.05339578294660896
Epoch 19/100, Loss: 0.05194808857049793
Epoch 20/100, Loss: 0.05002049694303423
Epoch 21/100, Loss: 0.04990276601165533
Epoch 22/100, Loss: 0.04838477016892284
Epoch 23/100, Loss: 0.048158988007344306
Epoch 24/100, Loss: 0.047704777447506785
Epoch 25/100, Loss: 0.04685406677890569
Epoch 26/100, Loss: 0.047475612023845315
Epoch 27/100, Loss: 0.045034552458673716
Epoch 28/100, Loss: 0.04540786822326481
Epoch 29/100, Loss: 0.04558467480819672
Epoch 30/100, Loss: 0.04475949553307146
Epoch 31/100, Loss: 0.04478358675260097
Epoch 32/100, Loss: 0.04609813040588051
Epoch 33/100, Loss: 0.044419451034627855
Epoch 34/100, Loss: 0.04591590980999172
Epoch 35/100, Loss: 0.04522771341726184
Epoch 36/100, Loss: 0.043583575054071844
Epoch 37/100, Loss: 0.04292562196496874
Epoch 38/100, Loss: 0.04304449330084026
Epoch 39/100, Loss: 0.04313726525288075
Epoch 40/100, Loss: 0.04403620329685509
Epoch 41/100, Loss: 0.04266846040263772
Epoch 42/100, Loss: 0.04353246605023742
Epoch 43/100, Loss: 0.042927936650812626
Epoch 44/100, Loss: 0.04265148483682424
Epoch 45/100, Loss: 0.04322906502056867
Epoch 46/100, Loss: 0.04265570093411952
Epoch 47/100, Loss: 0.04367442091461271
Epoch 48/100, Loss: 0.04249255021568388
Epoch 49/100, Loss: 0.04314922750927508
Epoch 50/100, Loss: 0.040937217068858445
Epoch 51/100, Loss: 0.04147053667111322
Epoch 52/100, Loss: 0.041322117671370506
Epoch 53/100, Loss: 0.041039843345060945
Epoch 54/100, Loss: 0.04153097188100219
Epoch 55/100, Loss: 0.04061295883730054
Epoch 56/100, Loss: 0.04211799812037498
Epoch 57/100, Loss: 0.0418203161098063
Epoch 58/100, Loss: 0.04216369381174445
Epoch 59/100, Loss: 0.0418102175462991
Epoch 60/100, Loss: 0.04128474835306406
Epoch 61/100, Loss: 0.04090912430547178
Epoch 62/100, Loss: 0.04149940062779933
Epoch 63/100, Loss: 0.04148677899502218
Epoch 64/100, Loss: 0.04039827117230743
Epoch 65/100, Loss: 0.041862635291181505
Epoch 66/100, Loss: 0.04087694582995027
Epoch 67/100, Loss: 0.040727682411670685
Epoch 68/100, Loss: 0.04185465176124126
Epoch 69/100, Loss: 0.04204046551603824
Epoch 70/100, Loss: 0.041481965919956565
Epoch 71/100, Loss: 0.04024235426913947
Epoch 72/100, Loss: 0.03970360767561942
Epoch 73/100, Loss: 0.040845963289029896
Epoch 74/100, Loss: 0.04132100322749466
Epoch 75/100, Loss: 0.0410688886186108
Epoch 76/100, Loss: 0.04151965316850692
Epoch 77/100, Loss: 0.04038135975133628
Epoch 78/100, Loss: 0.04175022023264319
Epoch 79/100, Loss: 0.04012780694756657
Epoch 80/100, Loss: 0.04044102120678872
Epoch 81/100, Loss: 0.04160262236837298
Epoch 82/100, Loss: 0.03993171313777566
Epoch 83/100, Loss: 0.04046281834598631
Epoch 84/100, Loss: 0.040426568244583905
Epoch 85/100, Loss: 0.04164401954039931
Epoch 86/100, Loss: 0.040596291539259255
Epoch 87/100, Loss: 0.0402101143845357
Epoch 88/100, Loss: 0.040164856472983956
Epoch 89/100, Loss: 0.039924598881043494
Epoch 90/100, Loss: 0.0390825467184186
Epoch 91/100, Loss: 0.040848852950148284
Epoch 92/100, Loss: 0.04037438798695803
Epoch 93/100, Loss: 0.04024903289973736
Epoch 94/100, Loss: 0.04031156509881839
Epoch 95/100, Loss: 0.03998025908367708
Epoch 96/100, Loss: 0.04034876299556345
Epoch 97/100, Loss: 0.041847138782031834
Epoch 98/100, Loss: 0.04048073245212436
Epoch 99/100, Loss: 0.040549472672864795
Epoch 100/100, Loss: 0.040236575179733336