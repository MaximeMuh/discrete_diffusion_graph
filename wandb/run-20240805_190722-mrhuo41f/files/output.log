tensor([[-0.1776,  0.0571,  0.2446,  0.0376,  0.0628,  0.1710,  0.0489, -0.0909,
          0.2634,  0.1752, -0.2212, -0.0201, -0.0939,  0.0819,  0.0447,  0.2421,
          0.1578, -0.1762, -0.0261, -0.0834,  0.0962,  0.1537,  0.1343,  0.0567],
        [-0.1586,  0.0388,  0.2501,  0.0322,  0.0518,  0.1390,  0.0738, -0.0810,
          0.2672,  0.1796, -0.2058, -0.0496, -0.0692,  0.0870,  0.0678,  0.2300,
          0.1476, -0.1998, -0.0413, -0.1031,  0.0973,  0.1749,  0.1397,  0.0518],
        [-0.1702,  0.0467,  0.2616,  0.0349,  0.0580,  0.1489,  0.0689, -0.0956,
          0.2708,  0.1724, -0.2094, -0.0385, -0.0661,  0.0892,  0.0892,  0.2285,
          0.1537, -0.2172, -0.0359, -0.1073,  0.0733,  0.1689,  0.1390,  0.0342],
        [-0.1728,  0.0437,  0.2450,  0.0279,  0.0562,  0.1663,  0.0621, -0.0887,
          0.2801,  0.1568, -0.2297, -0.0520, -0.0927,  0.1061,  0.0754,  0.2334,
          0.1566, -0.2058, -0.0407, -0.1019,  0.0866,  0.1576,  0.1442,  0.0485],
        [-0.1723,  0.0564,  0.2388,  0.0237,  0.0699,  0.1602,  0.0597, -0.0874,
          0.2699,  0.1661, -0.2201, -0.0539, -0.1011,  0.0987,  0.0696,  0.2328,
          0.1485, -0.1883, -0.0417, -0.1027,  0.0961,  0.1669,  0.1419,  0.0723],
        [-0.1708,  0.0542,  0.2379,  0.0333,  0.0874,  0.1720,  0.0729, -0.0999,
          0.2660,  0.1720, -0.2287, -0.0181, -0.1086,  0.0903,  0.0391,  0.2514,
          0.1559, -0.1551, -0.0249, -0.1034,  0.1270,  0.1460,  0.1429,  0.0681],
        [-0.1981,  0.0589,  0.2606,  0.0313,  0.0632,  0.1970,  0.0659, -0.1246,
          0.2802,  0.1591, -0.2348,  0.0096, -0.0940,  0.0850,  0.0564,  0.2480,
          0.1702, -0.1801, -0.0021, -0.0655,  0.0706,  0.1422,  0.1500,  0.0330],
        [-0.1635,  0.0265,  0.2473,  0.0196,  0.0371,  0.1726,  0.0635, -0.0987,
          0.2649,  0.1592, -0.2190, -0.0370, -0.0867,  0.1200,  0.0857,  0.2308,
          0.1657, -0.2069, -0.0426, -0.1026,  0.0904,  0.1597,  0.1285,  0.0387],
        [-0.1679,  0.0448,  0.2381,  0.0149,  0.0510,  0.1807,  0.0469, -0.1014,
          0.2551,  0.1603, -0.2186, -0.0352, -0.1025,  0.1143,  0.0715,  0.2340,
          0.1593, -0.1885, -0.0367, -0.0943,  0.0906,  0.1619,  0.1233,  0.0662],
        [-0.1946,  0.0563,  0.2371,  0.0310,  0.0653,  0.1434,  0.0685, -0.0626,
          0.2903,  0.1707, -0.2134, -0.0488, -0.0952,  0.0909,  0.0481,  0.2240,
          0.1466, -0.1811, -0.0545, -0.1018,  0.1139,  0.1514,  0.1638,  0.0760],
        [-0.1788,  0.0485,  0.2524,  0.0271,  0.0680,  0.1941,  0.0414, -0.1213,
          0.2529,  0.1506, -0.2275, -0.0089, -0.1044,  0.1212,  0.0632,  0.2395,
          0.1627, -0.2015, -0.0236, -0.0952,  0.0776,  0.1403,  0.1161,  0.0541],
        [-0.1647,  0.0509,  0.2457,  0.0278,  0.0743,  0.1746,  0.0634, -0.1233,
          0.2491,  0.1639, -0.2193, -0.0150, -0.0983,  0.1149,  0.0691,  0.2370,
          0.1561, -0.1803, -0.0206, -0.0962,  0.0881,  0.1571,  0.1218,  0.0589],
        [-0.1751,  0.0703,  0.2493,  0.0434,  0.0739,  0.1491,  0.0619, -0.0970,
          0.2668,  0.1805, -0.2288, -0.0316, -0.0862,  0.0713,  0.0517,  0.2474,
          0.1578, -0.1815, -0.0237, -0.0893,  0.0954,  0.1699,  0.1457,  0.0585],
        [-0.1847,  0.0444,  0.2530,  0.0241,  0.0621,  0.1787,  0.0516, -0.0925,
          0.2690,  0.1573, -0.2165, -0.0300, -0.0978,  0.1055,  0.0626,  0.2347,
          0.1543, -0.2034, -0.0358, -0.1016,  0.0875,  0.1444,  0.1343,  0.0602],
        [-0.1767,  0.0656,  0.2430,  0.0312,  0.0666,  0.1606,  0.0629, -0.0985,
          0.2729,  0.1679, -0.2214, -0.0319, -0.0915,  0.0910,  0.0493,  0.2384,
          0.1483, -0.1742, -0.0193, -0.0810,  0.0844,  0.1597,  0.1465,  0.0629],
        [-0.1538,  0.0309,  0.2350,  0.0333,  0.0510,  0.1766,  0.0543, -0.1133,
          0.2461,  0.1539, -0.2179, -0.0279, -0.0903,  0.1227,  0.0824,  0.2336,
          0.1659, -0.1882, -0.0295, -0.0926,  0.0928,  0.1528,  0.1149,  0.0568]],
       device='cuda:0', grad_fn=<AddmmBackward0>)
/home/mmuhleth/discrete_diffusion_graph/utils/graphs.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_matrix = loss_matrix * (1-2*torch.tensor(sigma_list).unsqueeze(-1).unsqueeze(-2).expand(grad_log_q_noise_list.size(0),grad_log_q_noise_list.size(1),grad_log_q_noise_list.size(2)).to(device)+1.0/len(sigma_list))
Traceback (most recent call last):
  File "/home/mmuhleth/discrete_diffusion_graph/train_vec.py", line 82, in <module>
    fit(model, optimizer, dataloader, max_epoch=200, device=device)
  File "/home/mmuhleth/discrete_diffusion_graph/train_vec.py", line 54, in fit
    l.backward()
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn