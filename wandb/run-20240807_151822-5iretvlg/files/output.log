/home/mmuhleth/discrete_diffusion_graph/utils/graphs.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_matrix = loss_matrix * (1-2*torch.tensor(sigma_list).unsqueeze(-1).unsqueeze(-2).expand(grad_log_q_noise_list.size(0),grad_log_q_noise_list.size(1),grad_log_q_noise_list.size(2)).to(device)+1.0/len(sigma_list))
/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 1/2000, Loss: 15.81187902178083
New best model saved with loss: 15.81187902178083
Epoch 2/2000, Loss: 15.224420888083321
New best model saved with loss: 15.224420888083321
Epoch 3/2000, Loss: 15.37227974240742
Epoch 4/2000, Loss: 15.424202737354097
Epoch 5/2000, Loss: 15.39437636874971
Epoch 6/2000, Loss: 15.497395893884084
Epoch 7/2000, Loss: 15.483804990374853
Epoch 8/2000, Loss: 15.208816747816782
New best model saved with loss: 15.208816747816782
Epoch 9/2000, Loss: 15.06052645425948
New best model saved with loss: 15.06052645425948
Epoch 10/2000, Loss: 15.647127605619884
Epoch 11/2000, Loss: 14.985457480899871
New best model saved with loss: 14.985457480899871
Epoch 12/2000, Loss: 15.96074743119497
Epoch 13/2000, Loss: 14.799480998326862
New best model saved with loss: 14.799480998326862
Epoch 14/2000, Loss: 15.122702538021027
Epoch 15/2000, Loss: 15.087169616941422
Epoch 16/2000, Loss: 14.968277424100846
Epoch 17/2000, Loss: 15.316182620941646
Epoch 18/2000, Loss: 15.487190170893593
Epoch 19/2000, Loss: 15.232182760087271
Epoch 20/2000, Loss: 14.89746948272463
Epoch 21/2000, Loss: 14.961553634159149
Epoch 22/2000, Loss: 15.169933939736987
Epoch 23/2000, Loss: 15.083855023459783
Epoch 24/2000, Loss: 15.476593532259502
Epoch 25/2000, Loss: 14.945557299114409
Epoch 26/2000, Loss: 15.10381825764974
Epoch 27/2000, Loss: 15.222457113720122
Epoch 28/2000, Loss: 15.355318311661009
Epoch 29/2000, Loss: 14.880707468305316
Epoch 30/2000, Loss: 15.024092734806121
Epoch 31/2000, Loss: 15.144181788913787
Epoch 32/2000, Loss: 14.582773526509603
New best model saved with loss: 14.582773526509603
Epoch 33/2000, Loss: 15.283299726153176
Epoch 34/2000, Loss: 15.273487734416175
Epoch 35/2000, Loss: 15.009353001912435
Epoch 36/2000, Loss: 15.211391320304266
Epoch 37/2000, Loss: 15.1458849150037
Epoch 38/2000, Loss: 14.802421736338783
Epoch 39/2000, Loss: 14.715157084994846
Epoch 40/2000, Loss: 14.955548180474175
Epoch 41/2000, Loss: 15.062253240555052
Epoch 42/2000, Loss: 15.125310163649301
Epoch 43/2000, Loss: 15.111763711959597
Epoch 44/2000, Loss: 14.80226559109158
Epoch 45/2000, Loss: 15.0901001824273
Epoch 46/2000, Loss: 14.953184385148306
Epoch 47/2000, Loss: 14.962020230671715
Epoch 48/2000, Loss: 14.993801207769485
Epoch 49/2000, Loss: 15.39627028268481
Epoch 50/2000, Loss: 15.117997949085538
Epoch 51/2000, Loss: 14.96940089028979
Epoch 52/2000, Loss: 14.972429487440321
Epoch 53/2000, Loss: 15.074778072417729
Epoch 54/2000, Loss: 15.001443499610538
Epoch 55/2000, Loss: 14.812395300183978
Epoch 56/2000, Loss: 15.219669039287265
Epoch 57/2000, Loss: 15.35246783968002
Epoch 58/2000, Loss: 15.176047620319185
Epoch 59/2000, Loss: 15.015344173189193
Epoch 60/2000, Loss: 14.902341464209178
Epoch 61/2000, Loss: 15.275508396209233
Epoch 62/2000, Loss: 15.22447116791256
Epoch 63/2000, Loss: 15.392151143815783
Traceback (most recent call last):
  File "/home/mmuhleth/discrete_diffusion_graph/train_ppgn/train_ppgn_simple_adj_neigh.py", line 104, in <module>
    fit(model, optimizer, dataloader, max_epoch=2000, device=device)
  File "/home/mmuhleth/discrete_diffusion_graph/train_ppgn/train_ppgn_simple_adj_neigh.py", line 56, in fit
    l.backward()
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt