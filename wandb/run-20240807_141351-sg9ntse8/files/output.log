/home/mmuhleth/discrete_diffusion_graph/utils/graphs.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  loss_matrix = loss_matrix * (1-2*torch.tensor(sigma_list).unsqueeze(-1).unsqueeze(-2).expand(grad_log_q_noise_list.size(0),grad_log_q_noise_list.size(1),grad_log_q_noise_list.size(2)).to(device)+1.0/len(sigma_list))
Epoch 1/2000, Loss: 0.11263734084786847
New best model saved with loss: 0.11263734084786847
/home/mmuhleth/miniconda3/envs/py38/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 2/2000, Loss: 0.03429060411872342
New best model saved with loss: 0.03429060411872342
Epoch 3/2000, Loss: 0.03380964382085949
New best model saved with loss: 0.03380964382085949
Epoch 4/2000, Loss: 0.03286042500985786
New best model saved with loss: 0.03286042500985786
Epoch 5/2000, Loss: 0.03296259790658951
Epoch 6/2000, Loss: 0.03329750651028007
Epoch 7/2000, Loss: 0.03242671227781102
New best model saved with loss: 0.03242671227781102
Epoch 8/2000, Loss: 0.03210569184739143
New best model saved with loss: 0.03210569184739143
Epoch 9/2000, Loss: 0.03255326865473762
Epoch 10/2000, Loss: 0.032695229921955615
Epoch 11/2000, Loss: 0.032289963914081454
Epoch 12/2000, Loss: 0.0326461351942271
Epoch 13/2000, Loss: 0.03240476729115471
Epoch 14/2000, Loss: 0.03288162243552506
Epoch 15/2000, Loss: 0.03243152634240687
Epoch 16/2000, Loss: 0.032308175694197416
Epoch 17/2000, Loss: 0.03130206867353991
New best model saved with loss: 0.03130206867353991
Epoch 18/2000, Loss: 0.03132435446605086
Epoch 19/2000, Loss: 0.03150289482437074
Epoch 20/2000, Loss: 0.03199562098598108
Epoch 21/2000, Loss: 0.03161893627839163
Epoch 22/2000, Loss: 0.03209028660785407
Epoch 23/2000, Loss: 0.03199338563717902
Epoch 24/2000, Loss: 0.03200351487612352
Epoch 25/2000, Loss: 0.03219502069987357
Epoch 26/2000, Loss: 0.03288282552966848
Epoch 27/2000, Loss: 0.03181166504509747
Epoch 28/2000, Loss: 0.03212036151671782
Epoch 29/2000, Loss: 0.03126021439675242
New best model saved with loss: 0.03126021439675242
Epoch 30/2000, Loss: 0.032209616736508906
Epoch 31/2000, Loss: 0.031189184344839305
New best model saved with loss: 0.031189184344839305
Epoch 32/2000, Loss: 0.03176558163249865
Epoch 33/2000, Loss: 0.030849155213218182
New best model saved with loss: 0.030849155213218182
Epoch 34/2000, Loss: 0.031400836538523436
Epoch 35/2000, Loss: 0.032018192287068814
Epoch 36/2000, Loss: 0.03177867113845423
Epoch 37/2000, Loss: 0.03078666637884453
New best model saved with loss: 0.03078666637884453
Epoch 38/2000, Loss: 0.03167537064291537
Epoch 39/2000, Loss: 0.03143929090583697
Epoch 40/2000, Loss: 0.030648313113488257
New best model saved with loss: 0.030648313113488257
Epoch 41/2000, Loss: 0.031143200816586614
Epoch 42/2000, Loss: 0.03141809144290164
Epoch 43/2000, Loss: 0.03135178313823417
Epoch 44/2000, Loss: 0.03170966578181833
Epoch 45/2000, Loss: 0.031534383655525744
Epoch 46/2000, Loss: 0.03192656789906323
Epoch 47/2000, Loss: 0.030912210524547845
Epoch 48/2000, Loss: 0.03207309800200164
Epoch 49/2000, Loss: 0.03185446240240708
Epoch 50/2000, Loss: 0.031666495255194604
Epoch 51/2000, Loss: 0.031662987370509654
Epoch 52/2000, Loss: 0.03158438915852457
Epoch 53/2000, Loss: 0.030046405910979956
New best model saved with loss: 0.030046405910979956
Epoch 54/2000, Loss: 0.032220725959632546
Epoch 55/2000, Loss: 0.030997410940472037
Epoch 56/2000, Loss: 0.03198395075742155
Epoch 57/2000, Loss: 0.03252426820108667
Epoch 58/2000, Loss: 0.03209557221271098
Epoch 59/2000, Loss: 0.030663882207591087
Epoch 60/2000, Loss: 0.03111958032241091
Epoch 61/2000, Loss: 0.031292606494389474
Epoch 62/2000, Loss: 0.03228838340146467
Epoch 63/2000, Loss: 0.03112952271476388
Epoch 64/2000, Loss: 0.0308443887042813
Epoch 65/2000, Loss: 0.03166583803249523
Epoch 66/2000, Loss: 0.03142601792933419
Epoch 67/2000, Loss: 0.03069133503595367
Epoch 68/2000, Loss: 0.031228480977006257
Epoch 69/2000, Loss: 0.031722959014587104
Epoch 70/2000, Loss: 0.0313668095623143
Epoch 71/2000, Loss: 0.031006809847895056
Epoch 72/2000, Loss: 0.03166760358726606
Epoch 73/2000, Loss: 0.031105003145057708
Epoch 74/2000, Loss: 0.030601879756432027
Epoch 75/2000, Loss: 0.030637758027296513
Epoch 76/2000, Loss: 0.03087033296469599
Epoch 77/2000, Loss: 0.03171542001655325
Epoch 78/2000, Loss: 0.030695448513142765
Epoch 79/2000, Loss: 0.031501718156505376
Epoch 80/2000, Loss: 0.03134437935659662
Epoch 81/2000, Loss: 0.03140912903472781
Epoch 82/2000, Loss: 0.031809559266548604
Epoch 83/2000, Loss: 0.031890167214442044
Epoch 84/2000, Loss: 0.03157317545264959
Epoch 85/2000, Loss: 0.030956769071053714
Epoch 86/2000, Loss: 0.03177873051026836
Epoch 87/2000, Loss: 0.03099546761950478
Epoch 88/2000, Loss: 0.030761097266804427
Epoch 89/2000, Loss: 0.03280834382167086
Epoch 90/2000, Loss: 0.031193903647363186
Epoch 91/2000, Loss: 0.03113563562510535
Epoch 92/2000, Loss: 0.03052398975705728
Epoch 93/2000, Loss: 0.030283932050224394
Epoch 94/2000, Loss: 0.03173909860197455
Epoch 95/2000, Loss: 0.030992168642114848
Epoch 96/2000, Loss: 0.03114235249813646
Epoch 97/2000, Loss: 0.03207550733350217
Epoch 98/2000, Loss: 0.03128856874536723
Epoch 99/2000, Loss: 0.03188170870998874
Epoch 100/2000, Loss: 0.03125275141792372
Epoch 101/2000, Loss: 0.03074105631094426
Epoch 102/2000, Loss: 0.032044473802670836
Epoch 103/2000, Loss: 0.031390497519169
Epoch 104/2000, Loss: 0.031167175562586635
Epoch 105/2000, Loss: 0.030813730496447533
Epoch 106/2000, Loss: 0.03195977065479383
Epoch 107/2000, Loss: 0.031398299033753574
Epoch 108/2000, Loss: 0.030737957451492548
Epoch 109/2000, Loss: 0.030809643969405442
Epoch 110/2000, Loss: 0.03103825874859467
Epoch 111/2000, Loss: 0.03092895809095353
Epoch 112/2000, Loss: 0.031113619275856763
Epoch 113/2000, Loss: 0.03204610716784373
Epoch 114/2000, Loss: 0.03136604052269831
Epoch 115/2000, Loss: 0.030912915128283203
Epoch 116/2000, Loss: 0.031109430885408074
Epoch 117/2000, Loss: 0.03170647012302652
Epoch 118/2000, Loss: 0.03175755380652845
Epoch 119/2000, Loss: 0.03146913682576269
Epoch 120/2000, Loss: 0.030273132142610848
Epoch 121/2000, Loss: 0.03113283810671419
Epoch 122/2000, Loss: 0.03118822496617213
Epoch 123/2000, Loss: 0.031990381015930325
Epoch 124/2000, Loss: 0.03175632987404242
Epoch 125/2000, Loss: 0.03126389812678099
Epoch 126/2000, Loss: 0.03145588090410456
Epoch 127/2000, Loss: 0.03193715895758942
Epoch 128/2000, Loss: 0.03097082959720865
Epoch 129/2000, Loss: 0.03135667054448277
Epoch 130/2000, Loss: 0.03097749943844974
Epoch 131/2000, Loss: 0.031552619591820985
Epoch 132/2000, Loss: 0.030921511352062225
Epoch 133/2000, Loss: 0.03141603042604402
Epoch 134/2000, Loss: 0.03154454531613737
Epoch 135/2000, Loss: 0.03217382211005315
Epoch 136/2000, Loss: 0.031865889381151646
Epoch 137/2000, Loss: 0.03121942625148222
Epoch 138/2000, Loss: 0.0321449757902883
Epoch 139/2000, Loss: 0.031369200034532696
Epoch 140/2000, Loss: 0.031750632100738585
Epoch 141/2000, Loss: 0.03143005311721936
Epoch 142/2000, Loss: 0.031247507024090737
Epoch 143/2000, Loss: 0.03145063586998731
Epoch 144/2000, Loss: 0.031644204747863114
Epoch 145/2000, Loss: 0.031619339308235794
Epoch 146/2000, Loss: 0.03138790570665151
Epoch 147/2000, Loss: 0.03229056909913197
Epoch 148/2000, Loss: 0.030852666008286178
Epoch 149/2000, Loss: 0.03126547485589981
